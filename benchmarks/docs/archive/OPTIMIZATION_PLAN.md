# Benchmarks ä¼˜åŒ–è®¡åˆ’

åŸºäºä½ çš„ä¸‰ä¸ªä¼˜ç§€è§‚å¯Ÿï¼Œè¿™é‡Œæ˜¯ä¼˜åŒ–å»ºè®®å’Œå®æ–½è®¡åˆ’ã€‚

---

## ğŸ“‹ é—®é¢˜åˆ†æ

### 1. âœ… requirements.txt å†—ä½™
- **ç°çŠ¶**: æœ‰ requirements.txt å’Œ pyproject.toml ä¸¤å¥—ä¾èµ–ç®¡ç†
- **é—®é¢˜**: å®¹æ˜“ä¸åŒæ­¥ï¼Œç»´æŠ¤æˆæœ¬é«˜
- **è§£å†³**: âœ… å·²å°† requirements.txt æ”¹ä¸º deprecation notice

### 2. âš ï¸ Shell è„šæœ¬æ··æ‚åœ¨ Python ä½“ç³»ä¸­
- **ç°çŠ¶**: 7 ä¸ª .sh è„šæœ¬ï¼ˆ1 ä¸ªå·¥å…· + 6 ä¸ªæ¼”ç¤ºï¼‰
- **é—®é¢˜**:
  - `test_scenarios/*.sh` æ˜¯æ¼”ç¤ºè„šæœ¬ï¼Œä¸»è¦ç”¨äºç”Ÿæˆäººç±»å¯è¯»çš„å¯¹æ¯”è¾“å‡º
  - `automation/quick_test.sh` æ˜¯ç”¨æˆ·å…¥å£ï¼Œä¾¿äºä¸€é”®è¿è¡Œ
- **æ˜¯å¦éœ€è¦æ”¹**: å–å†³äºä½¿ç”¨åœºæ™¯

### 3. ğŸ”§ ç©ºç›®å½•é—®é¢˜
- **ç°çŠ¶**: 12 ä¸ªç©ºç›®å½•
- **é—®é¢˜**: æœ‰äº›æ˜¯é¢„ç•™çš„æœªå®ç°åŠŸèƒ½ï¼Œæœ‰äº›æ˜¯ç¼ºå°‘æ•°æ®
- **éœ€è¦**: æ¸…ç† + æ·»åŠ  .gitkeep + è¡¥å……å®ç°

---

## ğŸ¯ ä¼˜åŒ–æ–¹æ¡ˆ

### Option A: æ¿€è¿›æ–¹æ¡ˆï¼ˆå®Œå…¨ Python åŒ–ï¼‰

**ä¼˜ç‚¹**: ç»Ÿä¸€æŠ€æœ¯æ ˆï¼Œæ˜“äºç»´æŠ¤
**ç¼ºç‚¹**: å¤±å» Shell è„šæœ¬çš„ç®€æ´æ€§å’Œæ¼”ç¤ºä»·å€¼

```
benchmarks/
â”œâ”€â”€ pyproject.toml              # å”¯ä¸€ä¾èµ–æ¥æº
â”œâ”€â”€ automation/
â”‚   â”œâ”€â”€ cli.py                  # æ›¿ä»£ quick_test.sh
â”‚   â””â”€â”€ scenario_runner.py      # æ›¿ä»£ test_scenarios/*.sh
â””â”€â”€ åˆ é™¤æ‰€æœ‰ .sh æ–‡ä»¶
```

### Option B: æ··åˆæ–¹æ¡ˆï¼ˆæ¨èï¼‰âœ…

**ä¼˜ç‚¹**: ä¿ç•™å„è‡ªä¼˜åŠ¿
**ç¼ºç‚¹**: éœ€è¦ç»´æŠ¤ä¸¤ç§è¯­è¨€

```
benchmarks/
â”œâ”€â”€ pyproject.toml              # Python ä¾èµ–
â”œâ”€â”€ requirements.txt            # Deprecated notice
â”œâ”€â”€ automation/
â”‚   â”œâ”€â”€ quick_test.sh          # ä¿ç•™ï¼šç”¨æˆ·å‹å¥½çš„å…¥å£
â”‚   â”œâ”€â”€ test_runner.py         # Python æ ¸å¿ƒ
â”‚   â””â”€â”€ cli.py                 # æ–°å¢ï¼šPython CLI æ¥å£
â””â”€â”€ test_scenarios/             # ä¿ç•™ï¼šæ¼”ç¤ºå’Œæ–‡æ¡£ä»·å€¼
    â”œâ”€â”€ *.sh                   # ä¿ç•™ï¼šç”Ÿæˆå¯è¯»å¯¹æ¯”è¾“å‡º
    â””â”€â”€ README.md              # æ–°å¢ï¼šè¯´æ˜è¿™äº›æ˜¯æ¼”ç¤ºè„šæœ¬
```

### Option C: æ¸…ç†æ–¹æ¡ˆï¼ˆæœ€å°æ”¹åŠ¨ï¼‰

åªæ¸…ç†ç©ºç›®å½•ï¼Œä¿æŒç°æœ‰ç»“æ„ã€‚

---

## ğŸ“Š è¯¦ç»†åˆ†æ

### 1. Shell è„šæœ¬çš„è§’è‰²

#### `automation/quick_test.sh` - ä¿ç•™ âœ…
**ç”¨é€”**: ç”¨æˆ·å…¥å£ï¼Œæä¾›å‹å¥½çš„ onboarding
**ä»·å€¼**:
- è‡ªåŠ¨æ£€æŸ¥ä¾èµ–ï¼ˆcs, uvï¼‰
- å‹å¥½çš„é”™è¯¯æç¤º
- é€‚åˆéæŠ€æœ¯ç”¨æˆ·

**æ›¿ä»£æ–¹æ¡ˆ**: åˆ›å»º Python CLI
```python
# benchmarks/automation/cli.py
import click

@click.command()
def quick_test():
    """Run quick benchmark test"""
    # æ£€æŸ¥ä¾èµ–
    # è¿è¡Œæµ‹è¯•
    # æ˜¾ç¤ºç»“æœ
```

**å»ºè®®**: ä¸¤è€…éƒ½ä¿ç•™
- `quick_test.sh` ç”¨äºå¿«é€Ÿä¸Šæ‰‹
- Python CLI ç”¨äºç¨‹åºåŒ–è°ƒç”¨

#### `test_scenarios/*.sh` - å¯é€‰ä¿ç•™ ğŸ¤”
**ç”¨é€”**: æ¼”ç¤ºè„šæœ¬ï¼Œç”Ÿæˆå¯¹æ¯”è¾“å‡º
**ä»·å€¼**:
- ç”¨äºæ–‡æ¡£å’Œåšå®¢
- ç”Ÿæˆ markdown å‹å¥½çš„è¾“å‡º
- å±•ç¤ºå®é™…ä½¿ç”¨åœºæ™¯

**é—®é¢˜**:
- ä¸æ˜¯è‡ªåŠ¨åŒ–æµ‹è¯•çš„ä¸€éƒ¨åˆ†
- ä¸ `automation/test_runner.py` åŠŸèƒ½é‡å¤

**æ›¿ä»£æ–¹æ¡ˆ**:
```python
# automation/scenario_runner.py
def run_scenario_01_error_handling():
    """æ¼”ç¤ºï¼šé”™è¯¯å¤„ç†å®¡è®¡"""
    print_header("Error Handling Audit")

    # Baseline
    print_section("Traditional grep (8 calls)")
    run_grep_baseline()

    # CS Hybrid
    print_section("cs --hybrid (1 call)")
    run_cs_hybrid()

    # Comparison
    print_comparison()
```

**å»ºè®®**:
- **çŸ­æœŸ**: ä¿ç•™ .sh è„šæœ¬ä½œä¸ºæ¼”ç¤º
- **é•¿æœŸ**: è¿ç§»åˆ° Python + rich åº“ç¾åŒ–è¾“å‡º

### 2. ç©ºç›®å½•åˆ†æ

| ç›®å½• | çŠ¶æ€ | ç”¨é€” | å»ºè®® |
|------|------|------|------|
| `automation/results/` | âœ… å¿…è¦ | test_runner.py è¾“å‡º | æ·»åŠ  .gitkeep |
| `real_world/results/` | âœ… å¿…è¦ | agent è¾“å‡º | æ·»åŠ  .gitkeep |
| `quantitative/results/` | âœ… å¿…è¦ | é‡åŒ–è¯„ä¼°è¾“å‡º | æ·»åŠ  .gitkeep |
| `automation/agents/` | âŒ å†—ä½™ | é‡å¤ real_world/agents | **åˆ é™¤** |
| `automation/datasets/` | âŒ å†—ä½™ | é‡å¤å…¶ä»– datasets | **åˆ é™¤** |
| `automation/eval/` | âŒ å†—ä½™ | é‡å¤ quantitative/eval | **åˆ é™¤** |
| `automation/tasks/` | âŒ å†—ä½™ | é‡å¤ real_world/tasks | **åˆ é™¤** |
| `quantitative/agents/` | â¸ï¸ æœªå®ç° | é¢„ç•™é‡åŒ–æµ‹è¯• agent | æ·»åŠ  README è¯´æ˜ |
| `quantitative/datasets/` | â¸ï¸ æœªå®ç° | é¢„ç•™ CodeSearchNet ç­‰æ•°æ®é›† | æ·»åŠ  README è¯´æ˜ |
| `quantitative/tasks/` | â¸ï¸ æœªå®ç° | é¢„ç•™é‡åŒ–ä»»åŠ¡å®šä¹‰ | æ·»åŠ  README è¯´æ˜ |
| `real_world/datasets/` | â¸ï¸ æœªå®ç° | é¢„ç•™å¤–éƒ¨ä»£ç åº“ | æ·»åŠ  README è¯´æ˜ |
| `real_world/eval/` | âŒ å†—ä½™ | è¯„ä¼°åœ¨ test_runner ä¸­ | **åˆ é™¤** |

---

## ğŸš€ å®æ–½å»ºè®®

### Phase 1: ç«‹å³æ¸…ç†ï¼ˆ5åˆ†é’Ÿï¼‰

```bash
cd /Users/arthur/dev-space/semcs/benchmarks

# 1. åˆ é™¤å†—ä½™ç©ºç›®å½•
rm -rf automation/agents automation/datasets automation/eval automation/tasks
rm -rf real_world/eval

# 2. ä¸ºå¿…è¦çš„ç©ºç›®å½•æ·»åŠ  .gitkeep
touch automation/results/.gitkeep
touch real_world/results/.gitkeep
touch quantitative/results/.gitkeep

# 3. ä¸ºæœªå®ç°çš„ç›®å½•æ·»åŠ  README
echo "# Quantitative Datasets (Future)" > quantitative/datasets/README.md
echo "# Quantitative Tasks (Future)" > quantitative/tasks/README.md
echo "# Real-world Test Repositories (Future)" > real_world/datasets/README.md
echo "# Quantitative Test Agents (Future)" > quantitative/agents/README.md
```

### Phase 2: æ·»åŠ  Python CLIï¼ˆ30åˆ†é’Ÿï¼‰

åˆ›å»º `automation/cli.py`:

```python
#!/usr/bin/env python3
"""
CS Benchmark CLI - Python interface for running benchmarks
"""
import click
import subprocess
import sys
from pathlib import Path

@click.group()
def cli():
    """CS Benchmark Suite - Automated testing for cs --hybrid"""
    pass

@cli.command()
@click.option('--max-tasks', type=int, default=3, help='Max tasks to run')
@click.option('--verbose', '-v', is_flag=True, help='Verbose output')
def quick(max_tasks, verbose):
    """Quick test (3 easy tasks by default)"""
    from test_runner import TestRunner

    # Check prerequisites
    if not check_cs_installed():
        click.echo("âŒ cs not installed", err=True)
        sys.exit(1)

    # Run test
    repo = Path(__file__).parent.parent.parent
    runner = TestRunner(repo, verbose=verbose)
    # ... run tests

@cli.command()
@click.option('--category', help='Filter by category')
@click.option('--difficulty', help='Filter by difficulty')
@click.option('--max-tasks', type=int, help='Max tasks to run')
@click.option('--verbose', '-v', is_flag=True)
def run(category, difficulty, max_tasks, verbose):
    """Run full benchmark"""
    # ... implementation

@cli.command()
def scenarios():
    """Run demonstration scenarios (replaces .sh scripts)"""
    click.echo("Running demonstration scenarios...")
    # Implementation

if __name__ == '__main__':
    cli()
```

æ·»åŠ åˆ° pyproject.toml:
```toml
[project.scripts]
cs-benchmark = "automation.cli:cli"
```

ä½¿ç”¨:
```bash
uv run cs-benchmark quick
uv run cs-benchmark run --category architecture
uv run cs-benchmark scenarios
```

### Phase 3: è¿ç§»æ¼”ç¤ºè„šæœ¬ï¼ˆå¯é€‰ï¼Œ1-2å°æ—¶ï¼‰

ä½¿ç”¨ `rich` åº“ç¾åŒ–è¾“å‡º:

```python
from rich.console import Console
from rich.table import Table
from rich.panel import Panel

console = Console()

def run_scenario_01():
    console.print(Panel("[bold]Test Scenario 1: Error Handling Audit[/bold]"))

    # Traditional approach
    table = Table(title="Traditional Approach (8 grep calls)")
    table.add_column("Step", style="cyan")
    table.add_column("Command", style="yellow")
    table.add_column("Results", style="green")

    table.add_row("1", "grep -r 'Result<'", "1,234 matches")
    # ...

    console.print(table)

    # CS Hybrid approach
    console.print("\n[bold green]âœ“ CS Hybrid (1 call)[/bold green]")
    # ...
```

---

## ğŸ¯ æ¨èæ–¹æ¡ˆ

### ç«‹å³æ‰§è¡Œï¼ˆä»Šå¤©ï¼‰

1. âœ… **å·²å®Œæˆ**: requirements.txt â†’ deprecation notice
2. ğŸ§¹ **æ¸…ç†ç©ºç›®å½•**: åˆ é™¤å†—ä½™ï¼Œæ·»åŠ  .gitkeep
3. ğŸ“ **æ·»åŠ è¯´æ˜**: ä¸ºæœªå®ç°ç›®å½•æ·»åŠ  README

### çŸ­æœŸï¼ˆæœ¬å‘¨ï¼‰

4. ğŸ **æ·»åŠ  Python CLI**: automation/cli.py
5. ğŸ“¦ **æ›´æ–° pyproject.toml**: æ·»åŠ  CLI å…¥å£ç‚¹
6. ğŸ“– **æ›´æ–°æ–‡æ¡£**: è¯´æ˜ Shell vs Python ä½¿ç”¨åœºæ™¯

### é•¿æœŸï¼ˆå¯é€‰ï¼‰

7. ğŸ¨ **è¿ç§»æ¼”ç¤ºè„šæœ¬**: test_scenarios/*.sh â†’ Python + rich
8. ğŸ§ª **å®ç°é‡åŒ–æµ‹è¯•**: quantitative/ å®Œæ•´å®ç°
9. ğŸ“Š **æ•°æ®é›†å‡†å¤‡**: ä¸‹è½½ CodeSearchNet ç­‰æ•°æ®é›†

---

## ğŸ“ æ–‡ä»¶ç»“æ„ä¼˜åŒ–å

```
benchmarks/
â”œâ”€â”€ pyproject.toml                    # å”¯ä¸€ä¾èµ–å®šä¹‰ âœ…
â”œâ”€â”€ requirements.txt                  # Deprecation notice âœ…
â”œâ”€â”€ .python-version                   # Python 3.11
â”œâ”€â”€ .gitignore                        # Python artifacts
â”‚
â”œâ”€â”€ automation/
â”‚   â”œâ”€â”€ cli.py                       # NEW: Python CLI å…¥å£
â”‚   â”œâ”€â”€ test_runner.py               # A/B æµ‹è¯•æ ¸å¿ƒ
â”‚   â”œâ”€â”€ quick_test.sh                # ä¿ç•™ï¼šç”¨æˆ·å‹å¥½å…¥å£
â”‚   â””â”€â”€ results/                     # æµ‹è¯•ç»“æœ
â”‚       â””â”€â”€ .gitkeep                 # NEW
â”‚
â”œâ”€â”€ real_world/
â”‚   â”œâ”€â”€ tasks/
â”‚   â”‚   â””â”€â”€ code_comprehension_tasks.yaml
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ baseline_agent.py
â”‚   â”‚   â””â”€â”€ cs_hybrid_agent.py
â”‚   â”œâ”€â”€ results/
â”‚   â”‚   â””â”€â”€ .gitkeep                 # NEW
â”‚   â””â”€â”€ datasets/
â”‚       â””â”€â”€ README.md                # NEW: è¯´æ˜æœªæ¥ç”¨é€”
â”‚
â”œâ”€â”€ quantitative/
â”‚   â”œâ”€â”€ eval/
â”‚   â”‚   â””â”€â”€ metrics.py
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â””â”€â”€ README.md                # NEW: è¯´æ˜æœªæ¥ç”¨é€”
â”‚   â”œâ”€â”€ tasks/
â”‚   â”‚   â””â”€â”€ README.md                # NEW
â”‚   â”œâ”€â”€ datasets/
â”‚   â”‚   â””â”€â”€ README.md                # NEW
â”‚   â””â”€â”€ results/
â”‚       â””â”€â”€ .gitkeep                 # NEW
â”‚
â”œâ”€â”€ test_scenarios/                   # å¯é€‰ä¿ç•™
â”‚   â”œâ”€â”€ README.md                    # NEW: è¯´æ˜è¿™äº›æ˜¯æ¼”ç¤ºè„šæœ¬
â”‚   â”œâ”€â”€ 01_error_handling_audit.sh   # æ¼”ç¤ºï¼šé”™è¯¯å¤„ç†
â”‚   â”œâ”€â”€ 02_config_system_trace.sh    # æ¼”ç¤ºï¼šé…ç½®è¿½è¸ª
â”‚   â”œâ”€â”€ 03_api_integration_locate.sh # æ¼”ç¤ºï¼šAPI å®šä½
â”‚   â”œâ”€â”€ 04_cross_language_refactor.sh # æ¼”ç¤ºï¼šè·¨è¯­è¨€
â”‚   â”œâ”€â”€ 05_recursive_navigation.sh   # æ¼”ç¤ºï¼šé€’å½’å¯¼èˆª
â”‚   â””â”€â”€ run_all_scenarios.sh         # è¿è¡Œæ‰€æœ‰æ¼”ç¤º
â”‚
â””â”€â”€ docs/                            # ä¿æŒä¸å˜
    â”œâ”€â”€ README.md
    â”œâ”€â”€ QUICK_START.md
    â”œâ”€â”€ QUICK_TEST_COMMANDS.md
    â””â”€â”€ ...
```

---

## â“ å†³ç­–ç‚¹

éœ€è¦ä½ ç¡®è®¤ï¼š

### Q1: Shell æ¼”ç¤ºè„šæœ¬æ€ä¹ˆå¤„ç†ï¼Ÿ

- [ ] **A**: å…¨éƒ¨ä¿ç•™ï¼ˆç®€å•ï¼Œä½†æŠ€æœ¯æ ˆæ··æ‚ï¼‰
- [ ] **B**: è¿ç§»åˆ° Python + richï¼ˆç»Ÿä¸€ï¼Œä½†éœ€è¦æ—¶é—´ï¼‰
- [ ] **C**: åªä¿ç•™ quick_test.shï¼Œåˆ é™¤æ¼”ç¤ºè„šæœ¬ï¼ˆæœ€æ¿€è¿›ï¼‰

**æˆ‘çš„å»ºè®®**: Bï¼ˆé•¿æœŸï¼‰æˆ– Aï¼ˆçŸ­æœŸè¿‡æ¸¡ï¼‰

### Q2: ç©ºç›®å½•æ¸…ç†ç­–ç•¥ï¼Ÿ

- [x] **æ¨è**: åˆ é™¤å†—ä½™ + ä¸ºå¿…è¦ç›®å½•æ·»åŠ  .gitkeep + ä¸ºæœªæ¥ç›®å½•æ·»åŠ  README
- [ ] **ä¿å®ˆ**: å…¨éƒ¨ä¿ç•™ï¼Œåªæ·»åŠ  README
- [ ] **æ¿€è¿›**: åˆ é™¤æ‰€æœ‰ç©ºç›®å½•ï¼Œéœ€è¦æ—¶å†åˆ›å»º

### Q3: CLI æ¥å£éœ€è¦å—ï¼Ÿ

- [ ] **Yes**: åˆ›å»º automation/cli.pyï¼Œç»Ÿä¸€ Python å…¥å£
- [ ] **No**: ä¿æŒç°çŠ¶ï¼Œåªç”¨ quick_test.sh + test_runner.py

**æˆ‘çš„å»ºè®®**: Yesï¼Œæä¾›æ›´å¥½çš„ç¼–ç¨‹æ¥å£

---

## ğŸ¬ ç«‹å³æ‰§è¡Œçš„å‘½ä»¤

å¦‚æœä½ åŒæ„ä¸Šè¿°å»ºè®®ï¼Œè¿è¡Œï¼š

```bash
cd /Users/arthur/dev-space/semcs/benchmarks

# æ¸…ç†å†—ä½™ç©ºç›®å½•
rm -rf automation/agents automation/datasets automation/eval automation/tasks real_world/eval

# æ·»åŠ  .gitkeep
touch automation/results/.gitkeep real_world/results/.gitkeep quantitative/results/.gitkeep

# æ·»åŠ æœªæ¥ç›®å½•çš„è¯´æ˜
cat > quantitative/datasets/README.md << 'EOF'
# Quantitative Datasets (Future Implementation)

This directory is reserved for standard code search datasets:

- CodeSearchNet extended format
- Custom code retrieval benchmarks
- Ground truth data for quantitative evaluation

**Status**: Not yet implemented
**Priority**: Medium (Phase 2 expansion)
EOF

cat > quantitative/tasks/README.md << 'EOF'
# Quantitative Tasks (Future Implementation)

This directory will contain:

- nl2code task definitions (natural language â†’ code)
- code2code task definitions (code â†’ related code)
- QA task definitions (question answering on code)

**Status**: Not yet implemented
**Priority**: Medium (Phase 2 expansion)
EOF

cat > real_world/datasets/README.md << 'EOF'
# Real-World Test Repositories (Future)

This directory is reserved for external codebases used in testing:

- rust-analyzer (large Rust codebase)
- tokio (async Rust runtime)
- typescript (TypeScript compiler)
- etc.

**Status**: Not yet implemented
**Priority**: Low (Phase 3 expansion)
EOF

cat > quantitative/agents/README.md << 'EOF'
# Quantitative Test Agents (Future)

Agent implementations for quantitative benchmarks:

- Baseline agents for standard datasets
- Comparison with ast-grep, ripgrep, etc.

**Status**: Not yet implemented
**Priority**: Medium (Phase 2 expansion)
EOF

cat > test_scenarios/README.md << 'EOF'
# Test Scenarios - Demonstration Scripts

These shell scripts are **demonstration tools**, not automated tests.

## Purpose

- Generate human-readable comparison output
- Used in documentation and blog posts
- Show real-world usage examples
- Compare cs --hybrid vs traditional grep/glob

## Usage

```bash
# Run individual scenario
./01_error_handling_audit.sh

# Run all scenarios
./run_all_scenarios.sh
```

## Automated Testing

For automated benchmarking, use the Python test runner:

```bash
cd ../automation
uv run python test_runner.py --verbose
```

## Future

These may be migrated to Python + rich library for better integration.
EOF

echo "âœ… Cleanup complete!"
```

---

**ä½ çš„é€‰æ‹©ï¼Ÿ** æˆ‘å¯ä»¥ç«‹å³æ‰§è¡Œä¸Šè¿°æ¸…ç†ï¼Œæˆ–è€…æ ¹æ®ä½ çš„åå¥½è°ƒæ•´æ–¹æ¡ˆã€‚
